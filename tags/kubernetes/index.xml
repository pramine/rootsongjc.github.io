<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jimmy Song - Cloud Native | Open Source | Community – kubernetes</title>
    <link>https://jimmysong.io/tags/kubernetes/</link>
    <description>Recent content in kubernetes on Jimmy Song - Cloud Native | Open Source | Community</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <copyright>Copyright &amp;copy; 2020 Jimmy Song 保留所有权利；基于 Hugo [educenter](https://github.com/themefisher/educenter-hugo)  主题构建</copyright>
    <lastBuildDate>Wed, 20 Dec 2017 15:08:02 +0800</lastBuildDate>
    
	  <atom:link href="https://jimmysong.io/tags/kubernetes/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>云原生应用之路</title>
      <link>https://jimmysong.io/blog/from-kubernetes-to-cloud-native/</link>
      <pubDate>Wed, 20 Dec 2017 15:08:02 +0800</pubDate>
      
      <guid>https://jimmysong.io/blog/from-kubernetes-to-cloud-native/</guid>
      <description>
        
        
        

&lt;p&gt;&lt;strong&gt;从Kubernetes到Cloud Native——云原生应用之路&lt;/strong&gt;，这是我最近在 &lt;a href=&#34;http://bj2017.archsummit.com/presentation/306&#34;&gt;ArchSummit2017北京站&lt;/a&gt; 和 &lt;a href=&#34;https://www.kubernetes.org.cn/3211.html&#34;&gt;数人云&amp;amp;TalkingData合办的Service Mesh is comming meetup&lt;/a&gt; 中分享的话题。&lt;/p&gt;

&lt;p&gt;本文简要介绍了容器技术发展的路径，为何Kubernetes的出现是容器技术发展到这一步的必然选择，而为何Kuberentes又将成为云原生应用的基石。&lt;/p&gt;

&lt;p&gt;我的分享按照这样的主线展开：容器-&amp;gt;Kubernetes-&amp;gt;微服务-&amp;gt;Cloud Native（云原生）-&amp;gt;Service Mesh（服务网格）-&amp;gt;使用场景-&amp;gt;Open Source（开源）。&lt;/p&gt;

&lt;h2 id=&#34;容器&#34;&gt;容器&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;容器——Cloud Native的基石&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;容器最初是通过开发者工具而流行，可以使用它来做隔离的开发测试环境和持续集成环境，这些都是因为容器轻量级，易于配置和使用带来的优势，docker和docker-compose这样的工具极大的方便的了应用开发环境的搭建，开发者就像是化学家一样在其中小心翼翼的进行各种调试和开发。&lt;/p&gt;

&lt;p&gt;随着容器的在开发者中的普及，已经大家对CI流程的熟悉，容器周边的各种工具蓬勃发展，俨然形成了一个小生态，在2016年达到顶峰，下面这张是我画的容器生态图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://jimmysong.io/kubernetes-handbook/images/container-ecosystem.png&#34; alt=&#34;容器生态图 Container ecosystem&#34; /&gt;&lt;/p&gt;

&lt;p&gt;该生态涵盖了容器应用中从镜像仓库、服务编排、安全管理、持续集成与发布、存储和网络管理等各个方面，随着在单主机中运行容器的成熟，集群管理和容器编排成为容器技术亟待解决的问题。譬如化学家在实验室中研究出来的新产品，如何推向市场，进行大规模生产，成了新的议题。&lt;/p&gt;

&lt;h2 id=&#34;为什么使用kubernetes&#34;&gt;为什么使用Kubernetes&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Kubernetes——让容器应用进入大规模工业生产。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Kubernetes是容器编排系统的事实标准&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在单机上运行容器，无法发挥它的最大效能，只有形成集群，才能最大程度发挥容器的良好隔离、资源分配与编排管理的优势，而对于容器的编排管理，Swarm、Mesos和Kubernetes的大战已经基本宣告结束，kubernetes成为了无可争议的赢家。&lt;/p&gt;

&lt;p&gt;下面这张图是Kubernetes的架构图（图片来自网络），其中显示了组件之间交互的接口CNI、CRI、OCI等，这些将Kubernetes与某款具体产品解耦，给用户最大的定制程度，使得Kubernetes有机会成为跨云的真正的云原生应用的操作系统。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://jimmysong.io/kubernetes-handbook/images/kubernetes-high-level-component-archtecture.jpg&#34; alt=&#34;Kuberentes架构&#34; /&gt;&lt;/p&gt;

&lt;p&gt;随着Kubernetes的日趋成熟，“Kubernetes is becoming boring”，基于该“操作系统”之上构建的适用于不同场景的应用将成为新的发展方向，就像我们将石油开采出来后，提炼出汽油、柴油、沥青等等，所有的材料都将找到自己的用途，Kubernetes也是，毕竟我们谁也不是为了部署和管理容器而用Kubernetes，承载其上的应用才是价值之所在。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;云原生的核心目标&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://jimmysong.io/kubernetes-handbook/images/cloud-native-core-target.jpg&#34; alt=&#34;Cloud Native Core target&#34; /&gt;&lt;/p&gt;

&lt;p&gt;云已经可以为我们提供稳定可以唾手可得的基础设施，但是业务上云成了一个难题，Kubernetes的出现与其说是从最初的容器编排解决方案，倒不如说是为了解决应用上云（即云原生应用）这个难题。&lt;/p&gt;

&lt;p&gt;包括微服务和FaaS/Serverless架构，都可以作为云原生应用的架构。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://jimmysong.io/kubernetes-handbook/images/redpoint-faas-landscape.jpg&#34; alt=&#34;FaaS Landscape&#34; /&gt;&lt;/p&gt;

&lt;p&gt;但就2017年为止，kubernetes的主要使用场景也主要作为应用开发测试环境、CI/CD和运行Web应用这几个领域，如下图&lt;a href=&#34;http://thenewstack.io&#34;&gt;TheNewStack&lt;/a&gt;的Kubernetes生态状况调查报告所示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://jimmysong.io/kubernetes-handbook/images/0069RVTdgy1fv5mxr6fxtj31kw11q484.jpg&#34; alt=&#34;Workloads running on Kubernetes&#34; /&gt;&lt;/p&gt;

&lt;p&gt;另外基于Kubernetes的构建PaaS平台和Serverless也处于爆发的准备的阶段，如下图中Gartner的报告中所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://jimmysong.io/kubernetes-handbook/images/0069RVTdgy1fv5my2jtxzj315o0z8dkr.jpg&#34; alt=&#34;Gartner技术爆发趋势图2017&#34; /&gt;&lt;/p&gt;

&lt;p&gt;当前各大公有云如Google GKE、微软Azure ACS、亚马逊EKS（2018年上线）、VmWare、Pivotal、腾讯云、阿里云等都提供了Kuberentes服务。&lt;/p&gt;

&lt;h2 id=&#34;微服务&#34;&gt;微服务&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;微服务——Cloud Native的应用架构。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;下图是&lt;a href=&#34;https://developers.redhat.com/blog/author/bibryam/&#34;&gt;Bilgin Ibryam&lt;/a&gt;给出的微服务中应该关心的主题，图片来自&lt;a href=&#34;https://developers.redhat.com/blog/2016/12/09/spring-cloud-for-microservices-compared-to-kubernetes/&#34;&gt;RedHat Developers&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://jimmysong.io/kubernetes-handbook/images/microservices-concerns.jpg&#34; alt=&#34;Microservices concerns&#34; /&gt;&lt;/p&gt;

&lt;p&gt;微服务带给我们很多开发和部署上的灵活性和技术多样性，但是也增加了服务调用的开销、分布式系统管理、调试与服务治理方面的难题。&lt;/p&gt;

&lt;p&gt;当前最成熟最完整的微服务框架可以说非&lt;a href=&#34;https://spring.io/&#34;&gt;Spring&lt;/a&gt;莫属，而Spring又仅限于Java语言开发，其架构本身又跟Kubernetes存在很多重合的部分，如何探索将Kubernetes作为微服务架构平台就成为一个热点话题。&lt;/p&gt;

&lt;p&gt;就拿微服务中最基础的&lt;strong&gt;服务注册发现&lt;/strong&gt;功能来说，其方式分为&lt;strong&gt;客户端服务发现&lt;/strong&gt;和&lt;strong&gt;服务端服务发现&lt;/strong&gt;两种，Java应用中常用的方式是使用Eureka和Ribbon做服务注册发现和负载均衡，这属于客户端服务发现，而在Kubernetes中则可以使用DNS、Service和Ingress来实现，不需要修改应用代码，直接从网络层面来实现。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://jimmysong.io/kubernetes-handbook/images/service-discovery-in-microservices.png&#34; alt=&#34;两种服务发现方式&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;cloud-native&#34;&gt;Cloud Native&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;DevOps——通向云原生的云梯&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;CNCF（云原生计算基金会）给出了云原生应用的三大特征：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;容器化包装&lt;/strong&gt;：软件应用的进程应该包装在容器中独立运行。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;动态管理&lt;/strong&gt;：通过集中式的编排调度系统来动态的管理和调度。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;微服务化&lt;/strong&gt;：明确服务间的依赖，互相解耦。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下图是我整理的关于云原生所需要的能力和特征。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://jimmysong.io/kubernetes-handbook/images/cloud-native-architecutre-mindnode.jpg&#34; alt=&#34;Cloud Native Features&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://cncf.io&#34;&gt;CNCF&lt;/a&gt;所托管的应用（目前已达12个），即朝着这个目标发展，其公布的&lt;a href=&#34;https://github.com/cncf/landscape&#34;&gt;Cloud Native Landscape&lt;/a&gt;，给出了云原生生态的参考体系。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://jimmysong.io/kubernetes-handbook/images/0069RVTdgy1fv5myp6ednj31kw0w0u0x.jpg&#34; alt=&#34;Cloud Native Landscape v1.0&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;使用Kubernetes构建云原生应用&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;我们都是知道Heroku推出了适用于PaaS的&lt;a href=&#34;https://12factor.net/&#34;&gt;12 factor app&lt;/a&gt;的规范，包括如下要素：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;基准代码&lt;/li&gt;
&lt;li&gt;依赖管理&lt;/li&gt;
&lt;li&gt;配置&lt;/li&gt;
&lt;li&gt;后端服务&lt;/li&gt;
&lt;li&gt;构建，发布，运行&lt;/li&gt;
&lt;li&gt;无状态进程&lt;/li&gt;
&lt;li&gt;端口绑定&lt;/li&gt;
&lt;li&gt;并发&lt;/li&gt;
&lt;li&gt;易处理&lt;/li&gt;
&lt;li&gt;开发环境与线上环境等价&lt;/li&gt;
&lt;li&gt;日志作为事件流&lt;/li&gt;
&lt;li&gt;管理进程&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;另外还有补充的三点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;API声明管理&lt;/li&gt;
&lt;li&gt;认证和授权&lt;/li&gt;
&lt;li&gt;监控与告警&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;如果落实的具体的工具，请看下图，使用Kubernetes构建云原生架构：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://jimmysong.io/kubernetes-handbook/images/building-cloud-native-architecture-with-kubernetes.png&#34; alt=&#34;Building a Cloud Native Architecture with Kubernetes followed 12 factor app&#34; /&gt;&lt;/p&gt;

&lt;p&gt;结合这12因素对开发或者改造后的应用适合部署到Kubernetes之上，基本流程如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://jimmysong.io/kubernetes-handbook/images/creating-kubernetes-native-app.jpg&#34; alt=&#34;Creating Kubernetes native app&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;迁移到云架构&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;迁移到云端架构，相对单体架构来说会带来很多挑战。比如自动的持续集成与发布、服务监控的变革、服务暴露、权限的管控等。这些具体细节请参考&lt;strong&gt;Kubernetes-handbook&lt;/strong&gt;中的说明：&lt;a href=&#34;https://jimmysong.io/kubernetes-handbook&#34;&gt;https://jimmysong.io/kubernetes-handbook&lt;/a&gt;，在此就不细节展开，另外推荐一本我翻译的由Pivotal出品的电子书——&lt;a href=&#34;https://content.pivotal.io/ebooks/migrating-to-cloud-native-application-architectures&#34;&gt;Migrating to Cloud Native Application Architectures&lt;/a&gt;，地址：&lt;a href=&#34;https://jimmysong.io/migrating-to-cloud-native-application-architectures/&#34;&gt;https://jimmysong.io/migrating-to-cloud-native-application-architectures/&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;service-mesh&#34;&gt;Service Mesh&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Services for show, meshes for a pro.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Kubernetes中的应用将作为微服务运行，但是Kuberentes本身并没有给出微服务治理的解决方案，比如服务的限流、熔断、良好的灰度发布支持等。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Service mesh可以用来做什么&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Traffic Management：API网关&lt;/li&gt;
&lt;li&gt;Observability：服务调用和性能分析&lt;/li&gt;
&lt;li&gt;Policy Enforcement：控制服务访问策略&lt;/li&gt;
&lt;li&gt;Service Identity and Security：安全保护&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Service mesh的特点&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;专用的基础设施层&lt;/li&gt;
&lt;li&gt;轻量级高性能网络代理&lt;/li&gt;
&lt;li&gt;提供安全的、快速的、可靠地服务间通讯&lt;/li&gt;
&lt;li&gt;扩展kubernetes的应用负载均衡机制，实现灰度发布&lt;/li&gt;
&lt;li&gt;完全解耦于应用，应用可以无感知，加速应用的微服务和云原生转型&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;使用Service Mesh将可以有效的治理Kuberentes中运行的服务，当前开源的Service Mesh有：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Linkderd：&lt;a href=&#34;https://linkerd.io&#34;&gt;https://linkerd.io&lt;/a&gt;，由最早提出Service Mesh的公司&lt;a href=&#34;https://buoyant.io&#34;&gt;Buoyant&lt;/a&gt;开源，创始人来自Twitter&lt;/li&gt;
&lt;li&gt;Envoy：&lt;a href=&#34;https://www.envoyproxy.io/&#34;&gt;https://www.envoyproxy.io/&lt;/a&gt;，Lyft开源的，可以在Istio中使用Sidecar模式运行&lt;/li&gt;
&lt;li&gt;Istio：&lt;a href=&#34;https://istio.io&#34;&gt;https://istio.io&lt;/a&gt;，由Google、IBM、Lyft联合开发并开源&lt;/li&gt;
&lt;li&gt;Conduit：&lt;a href=&#34;https://conduit.io&#34;&gt;https://conduit.io&lt;/a&gt;，同样由Buoyant开源的轻量级的基于Kubernetes的Service Mesh&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;此外还有很多其它的Service Mesh鱼贯而出，请参考&lt;a href=&#34;https://jimmysong.io/awesome-cloud-native&#34;&gt;awesome-cloud-native&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Istio VS Linkerd&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Linkerd和Istio是最早开源的Service Mesh，它们都支持Kubernetes，下面是它们之间的一些特性对比。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;Feature&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Istio&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Linkerd&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;部署架构&lt;/td&gt;
&lt;td&gt;Envoy/Sidecar&lt;/td&gt;
&lt;td&gt;DaemonSets&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;易用性&lt;/td&gt;
&lt;td&gt;复杂&lt;/td&gt;
&lt;td&gt;简单&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;支持平台&lt;/td&gt;
&lt;td&gt;kuberentes&lt;/td&gt;
&lt;td&gt;kubernetes/mesos/Istio/local&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;当前版本&lt;/td&gt;
&lt;td&gt;0.3.0&lt;/td&gt;
&lt;td&gt;1.3.3&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;是否已有生产部署&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;关于两者的架构可以参考各自的官方文档，我只从其在kubernetes上的部署结构来说明其区别。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://jimmysong.io/kubernetes-handbook/images/istio-vs-linkerd.jpg&#34; alt=&#34;istio vs linkerd&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Istio的组件复杂，可以分别部署的kubernetes集群中，但是作为核心路由组件&lt;strong&gt;Envoy&lt;/strong&gt;是以&lt;strong&gt;Sidecar&lt;/strong&gt;形式与应用运行在同一个Pod中的，所有进入该Pod中的流量都需要先经过Envoy。&lt;/p&gt;

&lt;p&gt;Linker的部署十分简单，本身就是一个镜像，使用Kubernetes的&lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/concepts/daemonset.html&#34;&gt;DaemonSet&lt;/a&gt;方式在每个node节点上运行。&lt;/p&gt;

&lt;p&gt;更多信息请参考&lt;a href=&#34;https://jimmysong.io/kubernetes-handbook&#34;&gt;kubernetes-handbook&lt;/a&gt;。&lt;/p&gt;

&lt;h2 id=&#34;使用场景&#34;&gt;使用场景&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Cloud Native的大规模工业生产&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;GitOps&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;给开发者带来最大配置和上线的灵活性，践行DevOps流程，改善研发效率，下图这样的情况将更少发生。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://jimmysong.io/kubernetes-handbook/images/0069RVTdgy1fv5mzj8rj6j318g1ewtfc.jpg&#34; alt=&#34;Deployment pipeline&#34; /&gt;&lt;/p&gt;

&lt;p&gt;我们知道Kubernetes中的所有应用的部署都是基于YAML文件的，这实际上就是一种&lt;strong&gt;Infrastructure as code&lt;/strong&gt;，完全可以通过Git来管控基础设施和部署环境的变更。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Big Data&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Spark现在已经非官方支持了基于Kuberentes的原生调度，其具有以下特点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Kubernetes原生调度：与yarn、mesos同级&lt;/li&gt;
&lt;li&gt;资源隔离，粒度更细：以namespace来划分用户&lt;/li&gt;
&lt;li&gt;监控的变革：单次任务资源计量&lt;/li&gt;
&lt;li&gt;日志的变革：pod的日志收集&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;Feature&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Yarn&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Kubernetes&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;queue&lt;/td&gt;
&lt;td&gt;queue&lt;/td&gt;
&lt;td&gt;namespace&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;instance&lt;/td&gt;
&lt;td&gt;ExcutorContainer&lt;/td&gt;
&lt;td&gt;Executor Pod&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;network&lt;/td&gt;
&lt;td&gt;host&lt;/td&gt;
&lt;td&gt;plugin&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;heterogeneous&lt;/td&gt;
&lt;td&gt;no&lt;/td&gt;
&lt;td&gt;yes&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;security&lt;/td&gt;
&lt;td&gt;RBAC&lt;/td&gt;
&lt;td&gt;ACL&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;下图是在Kubernetes上运行三种调度方式的spark的单个节点的应用部分对比：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://jimmysong.io/kubernetes-handbook/images/spark-on-kubernetes-with-different-schedulers.jpg&#34; alt=&#34;Spark on Kubernetes with different schedulers&#34; /&gt;&lt;/p&gt;

&lt;p&gt;从上图中可以看到在Kubernetes上使用YARN调度、standalone调度和kubernetes原生调度的方式，每个node节点上的Pod内的spark Executor分布，毫无疑问，使用kubernetes原生调度的spark任务才是最节省资源的。&lt;/p&gt;

&lt;p&gt;提交任务的语句看起来会像是这样的：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./spark-submit \
  --deploy-mode cluster \
  --class com.talkingdata.alluxio.hadooptest \
  --master k8s://https://172.20.0.113:6443 \
  --kubernetes-namespace spark-cluster \
  --conf spark.kubernetes.driverEnv.SPARK_USER=hadoop \
  --conf spark.kubernetes.driverEnv.HADOOP_USER_NAME=hadoop \
  --conf spark.executorEnv.HADOOP_USER_NAME=hadoop \
  --conf spark.executorEnv.SPARK_USER=hadoop \
  --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark \
  --conf spark.driver.memory=100G \
  --conf spark.executor.memory=10G \
  --conf spark.driver.cores=30 \
  --conf spark.executor.cores=2 \
  --conf spark.driver.maxResultSize=10240m \
  --conf spark.kubernetes.driver.limit.cores=32 \
  --conf spark.kubernetes.executor.limit.cores=3 \
  --conf spark.kubernetes.executor.memoryOverhead=2g \
  --conf spark.executor.instances=5 \
  --conf spark.app.name=spark-pi \
  --conf spark.kubernetes.driver.docker.image=spark-driver:v2.1.0-kubernetes-0.3.1-1 \
  --conf spark.kubernetes.executor.docker.image=spark-executor:v2.1.0-kubernetes-0.3.1-1 \
  --conf spark.kubernetes.initcontainer.docker.image=spark-init:v2.1.0-kubernetes-0.3.1-1 \
  --conf spark.kubernetes.resourceStagingServer.uri=http://172.20.0.114:31000 \
~/Downloads/tendcloud_2.10-1.0.jar
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;关于支持Kubernetes原生调度的Spark请参考：&lt;a href=&#34;https://jimmysong.io/spark-on-k8s/&#34;&gt;https://jimmysong.io/spark-on-k8s/&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;open-source&#34;&gt;Open Source&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Contributing is Not only about code, it is about helping a community.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;下图是我们刚调研准备使用Kubernetes时候的调研方案选择。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://jimmysong.io/kubernetes-handbook/images/0069RVTdgy1fv5mzywc83j31fk1i8qg4.jpg&#34; alt=&#34;Kubernetes solutions&#34; /&gt;&lt;/p&gt;

&lt;p&gt;对于一个初次接触Kubernetes的人来说，看到这样一个庞大的架构选型时会望而生畏，但是Kubernetes的开源社区帮助了我们很多。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://jimmysong.io/kubernetes-handbook/images/kubernetes-sigs.jpg&#34; alt=&#34;Kubernetes SIG&#34; /&gt;&lt;/p&gt;

&lt;p&gt;我组建了&lt;strong&gt;K8S&amp;amp;Cloud Native实战&lt;/strong&gt;微信群，参与了k8smeetup、KEUC2017、&lt;a href=&#34;https://github.com/kubernetes/kubernetes-docs-cn&#34;&gt;kubernetes-docs-cn&lt;/a&gt; Kubernetes官方中文文档项目。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;有用的资料和链接&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;我的博客： &lt;a href=&#34;https://jimmysong.io&#34;&gt;https://jimmysong.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;微信群：k8s&amp;amp;cloud native实战群（见：&lt;a href=&#34;https://jimmysong.io/about&#34;&gt;https://jimmysong.io/about&lt;/a&gt;）&lt;/li&gt;
&lt;li&gt;Meetup：k8smeetup&lt;/li&gt;
&lt;li&gt;Cloud Native Go - 基于Go和React云原生Web应用开发：&lt;a href=&#34;https://jimmysong.io/cloud-native-go&#34;&gt;https://jimmysong.io/cloud-native-go&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Gitbook：&lt;a href=&#34;https://jimmysong.io/kubernetes-handbook&#34;&gt;https://jimmysong.io/kubernetes-handbook&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Cloud native开源生态：&lt;a href=&#34;https://jimmysong.io/awesome-cloud-native/&#34;&gt;https://jimmysong.io/awesome-cloud-native/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;资料分享整理：&lt;a href=&#34;https://github.com/rootsongjc/cloud-native-slides-share&#34;&gt;https://github.com/rootsongjc/cloud-native-slides-share&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;迁移到云原生架构：&lt;a href=&#34;https://jimmysong.io/migrating-to-cloud-native-application-architectures/&#34;&gt;https://jimmysong.io/migrating-to-cloud-native-application-architectures/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;KubeCon + CloudNativeCon 2018年11月14-15日 上海&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>使用Helm安装Nginx ingress</title>
      <link>https://jimmysong.io/blog/install-nginx-ingress-with-helm/</link>
      <pubDate>Fri, 27 Oct 2017 19:10:59 +0800</pubDate>
      
      <guid>https://jimmysong.io/blog/install-nginx-ingress-with-helm/</guid>
      <description>
        
        
        

&lt;h1 id=&#34;使用helm安装nginx-ingress&#34;&gt;使用Helm安装Nginx ingress&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/kubernetes/ingress-nginx&#34;&gt;Nginx ingress&lt;/a&gt; 使用ConfigMap来管理Nginx配置，nginx是大家熟知的代理和负载均衡软件，比起&lt;a href=&#34;https://traefik.io&#34;&gt;Traefik&lt;/a&gt;来说功能更加强大，我们使用&lt;a href=&#34;http://helm.sh&#34;&gt;helm&lt;/a&gt;来部署，&lt;a href=&#34;https://github.com/kubernetes/charts&#34;&gt;chart&lt;/a&gt;保存在私有的仓库中，helm安装使用见&lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/practice/helm.html&#34;&gt;使用Helm管理kubernetes应用&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;安装时需要用到的镜像有：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;sophos/nginx-vts-exporter:v0.6&lt;/li&gt;
&lt;li&gt;gcr.io/google_containers/nginx-ingress-controller:0.9.0-beta.15&lt;/li&gt;
&lt;li&gt;gcr.io/google_containers/defaultbackend:1.3&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;gcr.io中的那个两个镜像我复制了一份到时速云，可供大家下载：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;index.tenxcloud.com/jimmy/defaultbackend:1.3&lt;/li&gt;
&lt;li&gt;index.tenxcloud.com/jimmy/nginx-ingress-controller:0.9.0-beta.15&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Docker hub上的那个镜像可以直接下载，所有的安装时需要的配置保存在&lt;a href=&#34;https://github.com/rootsongjc/kubernetes-handbook/blob/master/manifests/nginx-ingress&#34;&gt;../manifests/nginx-ingress&lt;/a&gt;目录下。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;安装nginx-ingress chart到本地repo中&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;修改&lt;code&gt;values.yaml&lt;/code&gt;配置，启用RBAC支持，相关配置见&lt;a href=&#34;https://github.com/kubernetes/charts/tree/master/stable/nginx-ingress#configuration&#34;&gt;nginx-ingress chart&lt;/a&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;helm package .
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;查看niginx-ingress&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ helm search nginx-ingress
NAME                	VERSION	DESCRIPTION
local/nginx-ingress 	0.8.9  	An nginx Ingress controller that uses ConfigMap...
stable/nginx-ingress	0.8.9  	An nginx Ingress controller that uses ConfigMap...
stable/nginx-lego   	0.3.0  	Chart for nginx-ingress-controller and kube-lego
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;使用helm部署nginx-ingress&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ helm install --name nginx-ingress local/nginx-ingress
NAME:   nginx-ingress
LAST DEPLOYED: Fri Oct 27 18:26:58 2017
NAMESPACE: default
STATUS: DEPLOYED

RESOURCES:
==&amp;gt; rbac.authorization.k8s.io/v1beta1/Role
NAME                         KIND
nginx-ingress-nginx-ingress  Role.v1beta1.rbac.authorization.k8s.io

==&amp;gt; rbac.authorization.k8s.io/v1beta1/RoleBinding
nginx-ingress-nginx-ingress  RoleBinding.v1beta1.rbac.authorization.k8s.io

==&amp;gt; v1/Service
NAME                                         CLUSTER-IP      EXTERNAL-IP  PORT(S)                     AGE
nginx-ingress-nginx-ingress-controller       10.254.100.108  &amp;lt;nodes&amp;gt;      80:30484/TCP,443:31053/TCP  1s
nginx-ingress-nginx-ingress-default-backend  10.254.58.156   &amp;lt;none&amp;gt;       80/TCP                      1s

==&amp;gt; extensions/v1beta1/Deployment
NAME                                         DESIRED  CURRENT  UP-TO-DATE  AVAILABLE  AGE
nginx-ingress-nginx-ingress-default-backend  1        1        1           0          1s
nginx-ingress-nginx-ingress-controller       1        1        1           0          1s

==&amp;gt; v1/ConfigMap
NAME                                    DATA  AGE
nginx-ingress-nginx-ingress-controller  1     1s

==&amp;gt; v1/ServiceAccount
NAME                         SECRETS  AGE
nginx-ingress-nginx-ingress  1        1s

==&amp;gt; rbac.authorization.k8s.io/v1beta1/ClusterRole
NAME                         KIND
nginx-ingress-nginx-ingress  ClusterRole.v1beta1.rbac.authorization.k8s.io

==&amp;gt; rbac.authorization.k8s.io/v1beta1/ClusterRoleBinding
nginx-ingress-nginx-ingress  ClusterRoleBinding.v1beta1.rbac.authorization.k8s.io


NOTES:
The nginx-ingress controller has been installed.
Get the application URL by running these commands:
  export HTTP_NODE_PORT=$(kubectl --namespace default get services -o jsonpath=&amp;quot;{.spec.ports[0].nodePort}&amp;quot; nginx-ingress-nginx-ingress-controller)
  export HTTPS_NODE_PORT=$(kubectl --namespace default get services -o jsonpath=&amp;quot;{.spec.ports[1].nodePort}&amp;quot; nginx-ingress-nginx-ingress-controller)
  export NODE_IP=$(kubectl --namespace default get nodes -o jsonpath=&amp;quot;{.items[0].status.addresses[1].address}&amp;quot;)

  echo &amp;quot;Visit http://$NODE_IP:$HTTP_NODE_PORT to access your application via HTTP.&amp;quot;
  echo &amp;quot;Visit https://$NODE_IP:$HTTPS_NODE_PORT to access your application via HTTPS.&amp;quot;

An example Ingress that makes use of the controller:

  apiVersion: extensions/v1beta1
  kind: Ingress
  metadata:
    annotations:
      kubernetes.io/ingress.class: nginx
    name: example
    namespace: foo
  spec:
    rules:
      - host: www.example.com
        http:
          paths:
            - backend:
                serviceName: exampleService
                servicePort: 80
              path: /
    # This section is only required if TLS is to be enabled for the Ingress
    tls:
        - hosts:
            - www.example.com
          secretName: example-tls

If TLS is enabled for the Ingress, a Secret containing the certificate and key must also be provided:

  apiVersion: v1
  kind: Secret
  metadata:
    name: example-tls
    namespace: foo
  data:
    tls.crt: &amp;lt;base64 encoded cert&amp;gt;
    tls.key: &amp;lt;base64 encoded key&amp;gt;
  type: kubernetes.io/tls
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;访问Nginx&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;首先获取Nginx的地址，从我们使用helm安装nginx-ingress命令的输出中那个可以看到提示，根据提示执行可以看到nginx的http和https地址：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;  export HTTP_NODE_PORT=$(kubectl --namespace default get services -o jsonpath=&amp;quot;{.spec.ports[0].nodePort}&amp;quot; nginx-ingress-nginx-ingress-controller)
  export HTTPS_NODE_PORT=$(kubectl --namespace default get services -o jsonpath=&amp;quot;{.spec.ports[1].nodePort}&amp;quot; nginx-ingress-nginx-ingress-controller)
  export NODE_IP=$(kubectl --namespace default get nodes -o jsonpath=&amp;quot;{.items[0].status.addresses[1].address}&amp;quot;)

  echo &amp;quot;Visit http://$NODE_IP:$HTTP_NODE_PORT to access your application via HTTP.&amp;quot;
  echo &amp;quot;Visit https://$NODE_IP:$HTTPS_NODE_PORT to access your application via HTTPS.&amp;quot;
  Visit http://172.20.0.113:30484 to access your application via HTTP.
  Visit https://172.20.0.113:31053 to access your application via HTTPS.
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;http地址：&lt;a href=&#34;http://172.20.0.113:30484&#34;&gt;http://172.20.0.113:30484&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;https地址：&lt;a href=&#34;https://172.20.0.113:31053&#34;&gt;https://172.20.0.113:31053&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们分别在http和https地址上测试一下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;/healthz&lt;/code&gt;返回200&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/&lt;/code&gt;返回404错误&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl -v http://172.20.0.113:30484/healthz
# 返回200
curl -v http://172.20.0.113:30484/
# 返回404
curl -v --insecure http://172.20.0.113:30484/healthz
# 返回200
curl -v --insecure http://172.20.0.113:30484/
# 返回404
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;删除nginx-ingress&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;helm delete --purge nginx-ingress
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用&lt;code&gt;--purge&lt;/code&gt;参数可以彻底删除release不留下记录，否则下一次部署的时候不能使用重名的release。&lt;/p&gt;

&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubernetes/ingress-nginx&#34;&gt;Ingress-nginx github&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kubernetes/charts/tree/master/stable/nginx-ingress&#34;&gt;Nginx chart configuration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/practice/helm.html&#34;&gt;使用Helm管理kubernetes应用&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>docker用户过渡到kubectl命令行指南</title>
      <link>https://jimmysong.io/blog/docker-cli-to-kubectl/</link>
      <pubDate>Sat, 16 Sep 2017 20:54:06 +0800</pubDate>
      
      <guid>https://jimmysong.io/blog/docker-cli-to-kubectl/</guid>
      <description>
        
        
        

&lt;p&gt;对于没有使用过 kubernetes 的 docker 用户，如何快速掌握 kubectl 命令？kubectl 跟 docker 命令之间有什么区别和联系？&lt;/p&gt;

&lt;p&gt;在本文中，我们将向 docker-cli 用户介绍 Kubernetes 命令行如何与 api 进行交互。该命令行工具——kubectl，被设计成 docker-cli 用户所熟悉的样子，但是它们之间又存在一些必要的差异。该文档将向您展示每个 docker 子命令和 kubectl 与其等效的命令。&lt;/p&gt;

&lt;p&gt;在使用 kubernetes 集群的时候，docker 命令通常情况是不需要用到的，只有在调试程序或者容器的时候用到，我们基本上使用 kubectl 命令即可，所以在操作 kubernetes 的时候我们抛弃原先使用 docker 时的一些观念。&lt;/p&gt;

&lt;h4 id=&#34;docker-run&#34;&gt;docker run&lt;/h4&gt;

&lt;p&gt;如何运行一个 nginx Deployment 并将其暴露出来？ 查看 &lt;a href=&#34;https://kubernetes.io/docs/user-guide/kubectl&#34;&gt;kubectl run&lt;/a&gt; 。&lt;/p&gt;

&lt;p&gt;使用 docker 命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker run -d --restart=always -e DOMAIN=cluster --name nginx-app -p 80:80 nginx
a9ec34d9878748d2f33dc20cb25c714ff21da8d40558b45bfaec9955859075d0
$ docker ps
CONTAINER ID        IMAGE               COMMAND                CREATED             STATUS              PORTS                         NAMES
a9ec34d98787        nginx               &amp;quot;nginx -g &#39;daemon of   2 seconds ago       Up 2 seconds        0.0.0.0:80-&amp;gt;80/tcp, 443/tcp   nginx-app 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用 kubectl 命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# start the pod running nginx
$ kubectl run --image=nginx nginx-app --port=80 --env=&amp;quot;DOMAIN=cluster&amp;quot;
deployment &amp;quot;nginx-app&amp;quot; created
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在大于等于 1.2 版本 Kubernetes 集群中，使用&lt;code&gt;kubectl run&lt;/code&gt; 命令将创建一个名为 &amp;ldquo;nginx-app&amp;rdquo; 的 Deployment。如果您运行的是老版本，将会创建一个 replication controller。 如果您想沿用旧的行为，使用 &lt;code&gt;--generation=run/v1&lt;/code&gt; 参数，这样就会创建 replication controller。查看 &lt;a href=&#34;https://kubernetes.io/docs/user-guide/kubectl/&#34;&gt;&lt;code&gt;kubectl run&lt;/code&gt;&lt;/a&gt; 获取更多详细信息。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# expose a port through with a service
$ kubectl expose deployment nginx-app --port=80 --name=nginx-http
service &amp;quot;nginx-http&amp;quot; exposed
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;在 kubectl 命令中，我们创建了一个 &lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/deployment&#34;&gt;Deployment&lt;/a&gt;，这将保证有 N 个运行 nginx 的 pod（N 代表 spec 中声明的 replica 数，默认为 1）。我们还创建了一个 &lt;a href=&#34;https://kubernetes.io/docs/user-guide/services&#34;&gt;service&lt;/a&gt;，使用 selector 匹配具有相应的 selector 的 Deployment。查看 &lt;a href=&#34;https://kubernetes.io/docs/user-guide/quick-start&#34;&gt;快速开始&lt;/a&gt; 获取更多信息。&lt;/p&gt;

&lt;p&gt;默认情况下镜像会在后台运行，与&lt;code&gt;docker run -d ...&lt;/code&gt; 类似，如果您想在前台运行，使用：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kubectl run [-i] [--tty] --attach &amp;lt;name&amp;gt; --image=&amp;lt;image&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;与 &lt;code&gt;docker run ...&lt;/code&gt; 不同的是，如果指定了 &lt;code&gt;--attach&lt;/code&gt; ，我们将连接到 &lt;code&gt;stdin&lt;/code&gt;，&lt;code&gt;stdout&lt;/code&gt; 和 &lt;code&gt;stderr&lt;/code&gt;，而不能控制具体连接到哪个输出流（&lt;code&gt;docker -a ...&lt;/code&gt;）。&lt;/p&gt;

&lt;p&gt;因为我们使用 Deployment 启动了容器，如果您终止了连接到的进程（例如 &lt;code&gt;ctrl-c&lt;/code&gt;），容器将会重启，这跟 &lt;code&gt;docker run -it&lt;/code&gt;不同。 如果想销毁该 Deployment（和它的 pod），您需要运行 &lt;code&gt;kubeclt delete deployment &amp;lt;name&amp;gt;&lt;/code&gt;。&lt;/p&gt;

&lt;h4 id=&#34;docker-ps&#34;&gt;docker ps&lt;/h4&gt;

&lt;p&gt;如何列出哪些正在运行？查看 &lt;a href=&#34;https://kubernetes.io/docs/user-guide/kubectl&#34;&gt;kubectl get&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;使用 docker 命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker ps
CONTAINER ID        IMAGE               COMMAND                CREATED             STATUS              PORTS                         NAMES
a9ec34d98787        nginx               &amp;quot;nginx -g &#39;daemon of   About an hour ago   Up About an hour    0.0.0.0:80-&amp;gt;80/tcp, 443/tcp   nginx-app
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用 kubectl 命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ kubectl get po
NAME              READY     STATUS    RESTARTS   AGE
nginx-app-5jyvm   1/1       Running   0          1h
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;docker-attach&#34;&gt;docker attach&lt;/h4&gt;

&lt;p&gt;如何连接到已经运行在容器中的进程？查看 &lt;a href=&#34;https://kubernetes.io/docs/user-guide/kubectl&#34;&gt;kubectl attach&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;使用 docker 命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker ps
CONTAINER ID        IMAGE               COMMAND                CREATED             STATUS              PORTS                         NAMES
a9ec34d98787        nginx               &amp;quot;nginx -g &#39;daemon of   8 minutes ago       Up 8 minutes        0.0.0.0:80-&amp;gt;80/tcp, 443/tcp   nginx-app
$ docker attach a9ec34d98787
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用 kubectl 命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ kubectl get pods
NAME              READY     STATUS    RESTARTS   AGE
nginx-app-5jyvm   1/1       Running   0          10m
$ kubectl attach -it nginx-app-5jyvm
...
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;docker-exec&#34;&gt;docker exec&lt;/h4&gt;

&lt;p&gt;如何在容器中执行命令？查看 &lt;a href=&#34;https://kubernetes.io/docs/user-guide/kubectl/&#34;&gt;kubectl exec&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;使用 docker 命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker ps
CONTAINER ID        IMAGE               COMMAND                CREATED             STATUS              PORTS                         NAMES
a9ec34d98787        nginx               &amp;quot;nginx -g &#39;daemon of   8 minutes ago       Up 8 minutes        0.0.0.0:80-&amp;gt;80/tcp, 443/tcp   nginx-app
$ docker exec a9ec34d98787 cat /etc/hostname
a9ec34d98787
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用 kubectl 命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ kubectl get po
NAME              READY     STATUS    RESTARTS   AGE
nginx-app-5jyvm   1/1       Running   0          10m
$ kubectl exec nginx-app-5jyvm -- cat /etc/hostname
nginx-app-5jyvm
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;执行交互式命令怎么办？&lt;/p&gt;

&lt;p&gt;使用 docker 命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker exec -ti a9ec34d98787 /bin/sh
# exit
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用 kubectl 命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ kubectl exec -ti nginx-app-5jyvm -- /bin/sh      
# exit
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;更多信息请查看 &lt;a href=&#34;https://kubernetes.io/docs/tasks/kubectl/get-shell-running-container&#34;&gt;获取运行中容器的 Shell 环境&lt;/a&gt;。&lt;/p&gt;

&lt;h4 id=&#34;docker-logs&#34;&gt;docker logs&lt;/h4&gt;

&lt;p&gt;如何查看运行中进程的 stdout/stderr？查看 &lt;a href=&#34;https://kubernetes.io/docs/user-guide/kubectl/&#34;&gt;kubectl logs&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;使用 docker 命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker logs -f a9e
192.168.9.1 - - [14/Jul/2015:01:04:02 +0000] &amp;quot;GET / HTTP/1.1&amp;quot; 200 612 &amp;quot;-&amp;quot; &amp;quot;curl/7.35.0&amp;quot; &amp;quot;-&amp;quot;
192.168.9.1 - - [14/Jul/2015:01:04:03 +0000] &amp;quot;GET / HTTP/1.1&amp;quot; 200 612 &amp;quot;-&amp;quot; &amp;quot;curl/7.35.0&amp;quot; &amp;quot;-&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用 kubectl 命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ kubectl logs -f nginx-app-zibvs
10.240.63.110 - - [14/Jul/2015:01:09:01 +0000] &amp;quot;GET / HTTP/1.1&amp;quot; 200 612 &amp;quot;-&amp;quot; &amp;quot;curl/7.26.0&amp;quot; &amp;quot;-&amp;quot;
10.240.63.110 - - [14/Jul/2015:01:09:02 +0000] &amp;quot;GET / HTTP/1.1&amp;quot; 200 612 &amp;quot;-&amp;quot; &amp;quot;curl/7.26.0&amp;quot; &amp;quot;-&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;现在是时候提一下 pod 和容器之间的细微差别了；默认情况下如果 pod 中的进程退出 pod 也不会终止，相反它将会重启该进程。这类似于 docker run 时的 &lt;code&gt;--restart=always&lt;/code&gt; 选项， 这是主要差别。在 docker 中，进程的每个调用的输出都是被连接起来的，但是对于 kubernetes，每个调用都是分开的。要查看以前在 kubernetes 中执行的输出，请执行以下操作：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ kubectl logs --previous nginx-app-zibvs
10.240.63.110 - - [14/Jul/2015:01:09:01 +0000] &amp;quot;GET / HTTP/1.1&amp;quot; 200 612 &amp;quot;-&amp;quot; &amp;quot;curl/7.26.0&amp;quot; &amp;quot;-&amp;quot;
10.240.63.110 - - [14/Jul/2015:01:09:02 +0000] &amp;quot;GET / HTTP/1.1&amp;quot; 200 612 &amp;quot;-&amp;quot; &amp;quot;curl/7.26.0&amp;quot; &amp;quot;-&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查看 &lt;a href=&#34;https://kubernetes.io/docs/concepts/cluster-administration/logging&#34;&gt;记录和监控集群活动&lt;/a&gt; 获取更多信息。&lt;/p&gt;

&lt;h4 id=&#34;docker-stop-和-docker-rm&#34;&gt;docker stop 和 docker rm&lt;/h4&gt;

&lt;p&gt;如何停止和删除运行中的进程？查看 &lt;a href=&#34;https://kubernetes.io/docs/user-guide/kubectl/&#34;&gt;kubectl delete&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;使用 docker 命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker ps
CONTAINER ID        IMAGE               COMMAND                CREATED             STATUS              PORTS                         NAMES
a9ec34d98787        nginx               &amp;quot;nginx -g &#39;daemon of   22 hours ago        Up 22 hours         0.0.0.0:80-&amp;gt;80/tcp, 443/tcp   nginx-app
$ docker stop a9ec34d98787
a9ec34d98787
$ docker rm a9ec34d98787
a9ec34d98787
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用 kubectl 命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ kubectl get deployment nginx-app
NAME        DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
nginx-app   1         1         1            1           2m
$ kubectl get po -l run=nginx-app
NAME                         READY     STATUS    RESTARTS   AGE
nginx-app-2883164633-aklf7   1/1       Running   0          2m
$ kubectl delete deployment nginx-app
deployment &amp;quot;nginx-app&amp;quot; deleted
$ kubectl get po -l run=nginx-app
# Return nothing
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;请注意，我们不直接删除 pod。使用 kubectl 命令，我们要删除拥有该 pod 的 Deployment。如果我们直接删除pod，Deployment 将会重新创建该 pod。&lt;/p&gt;

&lt;h4 id=&#34;docker-login&#34;&gt;docker login&lt;/h4&gt;

&lt;p&gt;在 kubectl 中没有对 &lt;code&gt;docker login&lt;/code&gt; 的直接模拟。如果您有兴趣在私有镜像仓库中使用 Kubernetes，请参阅 &lt;a href=&#34;https://kubernetes.io/docs/concepts/containers/images/#using-a-private-registry&#34;&gt;使用私有镜像仓库&lt;/a&gt;。&lt;/p&gt;

&lt;h4 id=&#34;docker-version&#34;&gt;docker version&lt;/h4&gt;

&lt;p&gt;如何查看客户端和服务端的版本？查看 &lt;a href=&#34;https://kubernetes.io/docs/user-guide/kubectl/&#34;&gt;kubectl version&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;使用 docker 命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker version
Client version: 1.7.0
Client API version: 1.19
Go version (client): go1.4.2
Git commit (client): 0baf609
OS/Arch (client): linux/amd64
Server version: 1.7.0
Server API version: 1.19
Go version (server): go1.4.2
Git commit (server): 0baf609
OS/Arch (server): linux/amd64
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用 kubectl 命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ kubectl version
Client Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;6&amp;quot;, GitVersion:&amp;quot;v1.6.9+a3d1dfa6f4335&amp;quot;, GitCommit:&amp;quot;9b77fed11a9843ce3780f70dd251e92901c43072&amp;quot;, GitTreeState:&amp;quot;dirty&amp;quot;, BuildDate:&amp;quot;2017-08-29T20:32:58Z&amp;quot;, OpenPaasKubernetesVersion:&amp;quot;v1.03.02&amp;quot;, GoVersion:&amp;quot;go1.7.5&amp;quot;, Compiler:&amp;quot;gc&amp;quot;, Platform:&amp;quot;linux/amd64&amp;quot;}
Server Version: version.Info{Major:&amp;quot;1&amp;quot;, Minor:&amp;quot;6&amp;quot;, GitVersion:&amp;quot;v1.6.9+a3d1dfa6f4335&amp;quot;, GitCommit:&amp;quot;9b77fed11a9843ce3780f70dd251e92901c43072&amp;quot;, GitTreeState:&amp;quot;dirty&amp;quot;, BuildDate:&amp;quot;2017-08-29T20:32:58Z&amp;quot;, OpenPaasKubernetesVersion:&amp;quot;v1.03.02&amp;quot;, GoVersion:&amp;quot;go1.7.5&amp;quot;, Compiler:&amp;quot;gc&amp;quot;, Platform:&amp;quot;linux/amd64&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;docker-info&#34;&gt;docker info&lt;/h4&gt;

&lt;p&gt;如何获取有关环境和配置的各种信息？查看 &lt;a href=&#34;https://kubernetes.io/docs/user-guide/kubectl/&#34;&gt;kubectl cluster-info&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;使用 docker 命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker info
Containers: 40
Images: 168
Storage Driver: aufs
 Root Dir: /usr/local/google/docker/aufs
 Backing Filesystem: extfs
 Dirs: 248
 Dirperm1 Supported: false
Execution Driver: native-0.2
Logging Driver: json-file
Kernel Version: 3.13.0-53-generic
Operating System: Ubuntu 14.04.2 LTS
CPUs: 12
Total Memory: 31.32 GiB
Name: k8s-is-fun.mtv.corp.google.com
ID: ADUV:GCYR:B3VJ:HMPO:LNPQ:KD5S:YKFQ:76VN:IANZ:7TFV:ZBF4:BYJO
WARNING: No swap limit support
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;使用 kubectl 命令：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ kubectl cluster-info
Kubernetes master is running at https://108.59.85.141
KubeDNS is running at https://108.59.85.141/api/v1/namespaces/kube-system/services/kube-dns/proxy
KubeUI is running at https://108.59.85.141/api/v1/namespaces/kube-system/services/kube-ui/proxy
Grafana is running at https://108.59.85.141/api/v1/namespaces/kube-system/services/monitoring-grafana/proxy
Heapster is running at https://108.59.85.141/api/v1/namespaces/kube-system/services/monitoring-heapster/proxy
InfluxDB is running at https://108.59.85.141/api/v1/namespaces/kube-system/services/monitoring-influxdb/proxy
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;本文同时归档到 &lt;a href=&#34;https://jimmysong.io/kubernetes-handbook&#34;&gt;kubernetes-handbook&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/rootsongjc/kubernetes.github.io/blob/master/docs/user-guide/docker-cli-to-kubectl.md&#34;&gt;阅读原文&lt;/a&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>记一本关于kubernetes management design patterns的书</title>
      <link>https://jimmysong.io/blog/book-kubernetes-management-design-patterns/</link>
      <pubDate>Thu, 20 Jul 2017 18:21:18 +0800</pubDate>
      
      <guid>https://jimmysong.io/blog/book-kubernetes-management-design-patterns/</guid>
      <description>
        
        
        

&lt;p&gt;下面是这本书的基本信息。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;书名： Kubernetes Management Design Patterns: With Docker, CoreOS Linux, and Other Platforms&lt;/li&gt;
&lt;li&gt;Amazon购买链接：&lt;a href=&#34;https://www.amazon.com/Kubernetes-Management-Design-Patterns-Platforms-ebook/dp/B01MZDO0BD/ref=pd_sbs_351_4?_encoding=UTF8&amp;amp;psc=1&amp;amp;refRID=79F47CR67EEESD35S2VF&#34;&gt;链接&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;作者：Deepak Vohra&lt;/li&gt;
&lt;li&gt;发行日期：2017年1月20日&lt;/li&gt;
&lt;li&gt;出版社：Apress&lt;/li&gt;
&lt;li&gt;页数：399&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;简介&#34;&gt;简介&lt;/h3&gt;

&lt;p&gt;Kubernetes引领容器集群管理进入一个全新的阶段；学习如何在CoreOS上配置和管理kubernetes集群；使用适当的管理模式，如ConfigMaps、Autoscaling、弹性资源使用和高可用性配置。讨论了kubernetes的一些其他特性，如日志、调度、滚动升级、volume、服务类型和跨多个云供应商zone。&lt;/p&gt;

&lt;p&gt;Kubernetes中的最小模块化单位是Pod，它是拥有共同的文件系统和网络的系列容器的集合。Pod的抽象层可以对容器使用设计模式，就像面向对象设计模式一样。容器能够提供与软件对象（如模块化或包装，抽象和重用）相同的优势。&lt;/p&gt;

&lt;p&gt;在大多数章节中使用的都是CoreOS Linux，其他讨论的平台有CentOS，OpenShift，Debian 8（jessie），AWS和Debian 7 for Google Container Engine。&lt;/p&gt;

&lt;p&gt;使用CoreOS主要是因为Docker已经在CoreOS上开箱即用。CoreOS：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;支持大多数云提供商（包括Amazon AWS EC2和Google Cloud Platform）和虚拟化平台（如VMWare和VirtualBox）&lt;/li&gt;
&lt;li&gt;提供Cloud-Config，用于声明式配置OS，如网络配置（flannel），存储（etcd）和用户帐户&lt;/li&gt;
&lt;li&gt;为容器化应用提供生产级基础架构，包括自动化，安全性和可扩展性&lt;/li&gt;
&lt;li&gt;引领容器行业标准，并建立了应用程序标准&lt;/li&gt;
&lt;li&gt;提供最先进的容器仓库，Quay&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Docker于2013年3月开源，现已称为最流行的容器平台。kubernetes于2014年6月开源，现在已经成为最流行的容器集群管理平台。第一个稳定版CoreOS Linux于2014年7月发行，现已成为最流行的容器操作系统之一。&lt;/p&gt;

&lt;h3 id=&#34;你将学到什么&#34;&gt;你将学到什么&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;使用docker和kubernetes&lt;/li&gt;
&lt;li&gt;在AWS和CoreOS上创建kubernetes集群&lt;/li&gt;
&lt;li&gt;应用集群管理设计模式&lt;/li&gt;
&lt;li&gt;使用多个云供应商zone&lt;/li&gt;
&lt;li&gt;使用Ansible管理kubernetes&lt;/li&gt;
&lt;li&gt;基于kubernetes的PAAS平台OpenShift&lt;/li&gt;
&lt;li&gt;创建高可用网站&lt;/li&gt;
&lt;li&gt;构建高可用用的kubernetes master集群&lt;/li&gt;
&lt;li&gt;使用volume、configmap、serivce、autoscaling和rolling update&lt;/li&gt;
&lt;li&gt;管理计算资源&lt;/li&gt;
&lt;li&gt;配置日志和调度&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;谁适合读这本书&#34;&gt;谁适合读这本书&lt;/h3&gt;

&lt;p&gt;Linux管理员、CoreOS管理员、应用程序开发者、容器即服务（CAAS）开发者。阅读这本书需要Linux和Docker的前置知识。介绍Kubernetes的知识，例如创建集群，创建Pod，创建service以及创建和缩放replication controller。还需要一些关于使用Amazon Web Services（AWS）EC2，CloudFormation和VPC的必备知识。&lt;/p&gt;

&lt;h3 id=&#34;关于作者&#34;&gt;关于作者&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Deepak Vohra&lt;/strong&gt; is an Oracle Certified Associate and a Sun Certified Java Programmer. Deepak has published in Oracle Magazine, OTN, IBM developerWorks, ONJava, DevSource,  WebLogic Developer’s Journal, XML Journal, Java Developer’s Journal, FTPOnline, and devx.&lt;/p&gt;

&lt;h3 id=&#34;目录&#34;&gt;目录&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;第一部分：平台

&lt;ul&gt;
&lt;li&gt;第1章：Kuberentes on AWS&lt;/li&gt;
&lt;li&gt;第2章：kubernetes on CoreOS on AWS&lt;/li&gt;
&lt;li&gt;第3章：kubernetes on Google Cloud Platform&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;第二部分：管理和配置

&lt;ul&gt;
&lt;li&gt;第4章：使用多个可用区&lt;/li&gt;
&lt;li&gt;第5章：使用Tectonic Console&lt;/li&gt;
&lt;li&gt;第6章：使用volume&lt;/li&gt;
&lt;li&gt;第7章：使用service&lt;/li&gt;
&lt;li&gt;第8章：使用Rolling updte&lt;/li&gt;
&lt;li&gt;第9章：在node上调度pod&lt;/li&gt;
&lt;li&gt;第10章：配置计算资源&lt;/li&gt;
&lt;li&gt;第11章：使用ConfigMap&lt;/li&gt;
&lt;li&gt;第12章：使用资源配额&lt;/li&gt;
&lt;li&gt;第13章：使用Autoscaling&lt;/li&gt;
&lt;li&gt;第14章：配置logging&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;第三部分：高可用

&lt;ul&gt;
&lt;li&gt;第15章：在OpenShift中使用HA master&lt;/li&gt;
&lt;li&gt;第16章：开发高可用网站&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;个人评价&#34;&gt;个人评价&lt;/h3&gt;

&lt;p&gt;本书更像是一本参考手册，对于想在公有云中（如AWS、Google Cloud Platform）中尝试Kubernetes的人会有所帮助，而对于想使用kubernetes进行自己的私有云建设，或想了解kubernetes的实现原理和技术细节的人来说，就不适合了。对我来说，本书中有个别几个章节可以参考，如高可用，但还是使用OpenShift实现的。总之，如果你使用AWS这样的公有云，对操作系统没有特别要求，可以接受CoreOS的话，那么可以看看这本书。本来本书会对kubernetes中的各种应用模式能够有个详解，但是从书中我并没有找到。&lt;/p&gt;

&lt;p&gt;本书有两个优点，一个是每个章节都给出了问题的起因和kubernetes的解决方案，二是几乎所有的命令和操作都附有截图，说明很详细。&lt;/p&gt;

      </description>
    </item>
    
  </channel>
</rss>
